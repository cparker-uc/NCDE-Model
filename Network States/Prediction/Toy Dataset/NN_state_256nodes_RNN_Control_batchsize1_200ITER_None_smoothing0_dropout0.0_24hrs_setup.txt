Model Setup for {PATIENT_GROUPS} Trained Network:

RNN Network Architecture Parameters
Input channels=1
Hidden channels=256
Output channels=1

Training hyperparameters
Optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 0.0
)Training Iterations=200
Learning rate=0.0003
Weight decay=0.0
Optimizer reset frequency=None

Dropout probability (after initial linear layer before NCDE): 0.0
Training Data Selection Parameters
(If not virtual, the only important params are the groups and whether data was normalized/standardized)
Patient groups=['Control']
Augmentation strategy=Uniform
Noise Magnitude=0.0
Normalized/standardized=None
Number of virtual patients per real patient=1
Label smoothing factor=0
Test Patient Combinations:
Control: None
MDD: None
Training batch size=1
Training Results:
Runtime=83.65238189697266
Loss over time=[(0, 31.894119262695312), (0, 31.316017150878906), (0, 30.34444236755371), (0, 28.784643173217773), (0, 27.130210876464844), (0, 26.064422607421875), (0, 25.263051986694336), (0, 24.38018226623535), (0, 23.49773406982422), (0, 22.84271240234375), (0, 22.20819664001465), (0, 21.676239013671875), (0, 21.280048370361328), (0, 20.94730567932129), (0, 20.57932472229004), (0, 20.167564392089844), (0, 19.66889762878418), (0, 19.215965270996094), (0, 18.974260330200195), (0, 18.744169235229492), (0, 18.492860794067383), (0, 18.26059341430664), (0, 18.084596633911133), (0, 17.84424591064453), (0, 17.570045471191406), (0, 17.288707733154297), (0, 16.983797073364258), (0, 16.621734619140625), (0, 16.35896873474121), (0, 16.241403579711914), (0, 16.15020179748535), (0, 16.051149368286133), (0, 15.970633506774902), (0, 15.888567924499512), (0, 15.796699523925781), (0, 15.701367378234863), (0, 15.606419563293457), (0, 15.506840705871582), (0, 15.367648124694824), (0, 15.096430778503418), (0, 14.886767387390137), (0, 14.773174285888672), (0, 14.689263343811035), (0, 14.615787506103516), (0, 14.54544448852539), (0, 14.480488777160645), (0, 14.420844078063965), (0, 14.362849235534668), (0, 14.309410095214844), (0, 14.263867378234863), (0, 14.225635528564453), (0, 14.189289093017578), (0, 14.16148853302002), (0, 14.128372192382812), (0, 14.08916187286377), (0, 14.049906730651855), (0, 14.017688751220703), (0, 13.98498821258545), (0, 13.950423240661621), (0, 13.916958808898926), (0, 13.88628101348877), (0, 13.85628890991211), (0, 13.823097229003906), (0, 13.788875579833984), (0, 13.756381034851074), (0, 13.725869178771973), (0, 13.697064399719238), (0, 13.670125007629395), (0, 13.64471435546875), (0, 13.6201171875), (0, 13.59646224975586), (0, 13.57343578338623), (0, 13.549818992614746), (0, 13.52647876739502), (0, 13.504180908203125), (0, 13.482436180114746), (0, 13.46078872680664), (0, 13.439362525939941), (0, 13.41838550567627), (0, 13.397811889648438), (0, 13.377537727355957), (0, 13.357413291931152), (0, 13.337417602539062), (0, 13.317584991455078), (0, 13.297779083251953), (0, 13.278038024902344), (0, 13.258605003356934), (0, 13.239394187927246), (0, 13.220821380615234), (0, 13.202743530273438), (0, 13.184856414794922), (0, 13.167574882507324), (0, 13.150497436523438), (0, 13.133323669433594), (0, 13.115405082702637), (0, 13.0960111618042), (0, 13.074795722961426), (0, 13.079676628112793), (0, 13.220669746398926), (0, 13.180500984191895), (0, 13.104409217834473), (0, 13.07708740234375), (0, 13.061481475830078), (0, 13.059314727783203), (0, 13.065925598144531), (0, 13.043045997619629), (0, 13.005085945129395), (0, 12.973915100097656), (0, 12.95306396484375), (0, 12.923927307128906), (0, 12.905387878417969), (0, 12.85309886932373), (0, 12.837519645690918), (0, 12.791889190673828), (0, 12.848739624023438), (0, 12.796481132507324), (0, 12.813492774963379), (0, 12.729740142822266), (0, 12.663310050964355), (0, 12.591965675354004), (0, 12.535321235656738), (0, 12.610743522644043), (0, 12.378312110900879), (0, 60.95823669433594), (0, 27.046579360961914), (0, 13.63643741607666), (0, 13.105128288269043), (0, 13.28646469116211), (0, 13.281798362731934), (0, 13.219405174255371), (0, 13.223603248596191), (0, 13.296088218688965), (0, 13.3350248336792), (0, 13.209166526794434), (0, 13.163300514221191), (0, 13.172419548034668), (0, 13.186867713928223), (0, 13.176465034484863), (0, 13.099190711975098), (0, 13.005484580993652), (0, 12.890925407409668), (0, 12.764732360839844), (0, 12.627971649169922), (0, 12.464428901672363), (0, 12.260647773742676), (0, 12.043289184570312), (0, 11.8468599319458), (0, 11.684128761291504), (0, 11.55297565460205), (0, 11.445297241210938), (0, 11.354823112487793), (0, 11.277587890625), (0, 11.210762023925781), (0, 11.154826164245605), (0, 11.1118803024292), (0, 11.078618049621582), (0, 11.045649528503418), (0, 11.008490562438965), (0, 10.97211742401123), (0, 10.941874504089355), (0, 10.917228698730469), (0, 10.893962860107422), (0, 10.868557929992676), (0, 10.840789794921875), (0, 10.81344985961914), (0, 10.789837837219238), (0, 10.770919799804688), (0, 10.754314422607422), (0, 10.736828804016113), (0, 10.717814445495605), (0, 10.698176383972168), (0, 10.67822265625), (0, 10.658039093017578), (0, 10.638282775878906), (0, 10.618391990661621), (0, 10.597268104553223), (0, 10.575701713562012), (0, 10.55465030670166), (0, 10.532474517822266), (0, 10.508843421936035), (0, 10.484573364257812), (0, 10.459015846252441), (0, 10.430974006652832), (0, 10.402572631835938), (0, 10.378201484680176), (0, 10.351668357849121), (0, 10.318985939025879), (0, 10.286885261535645), (0, 10.255457878112793), (0, 10.228282928466797), (0, 10.200185775756836), (0, 10.159319877624512), (0, 10.1134672164917), (0, 10.06564712524414), (0, 10.060439109802246), (0, 10.475602149963379), (0, 10.074244499206543), (0, 10.137802124023438), (0, 10.099946975708008), (0, 10.128474235534668)]