Model Setup for {PATIENT_GROUPS} Trained Network:

{NETWORK_TYPE} Network Architecture Parameters
Input channels=1
Hidden channels=256
Output channels=4

Training hyperparameters
Optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.003
    maximize: False
    weight_decay: 1e-06
)Training Iterations=10
Learning rate=0.003
Weight decay=1e-06
Optimizer reset frequency=None

Dropout probability (after initial linear layer before NCDE): 0.0
Training Data Selection Parameters
(If not virtual, the only important params are the groups and whether data was normalized/standardized)
Patient groups=['Control']
Augmentation strategy=Uniform
Noise Magnitude=0.0
Normalized/standardized=None
Number of virtual patients per real patient=100
Label smoothing factor=0
Test Patient Combinations:
Control: None
MDD: None
Training batch size=1
Training Results:
Runtime=32.40166711807251
Loss over time=[(0, 19.17737381274709), (0, 41.05293244912787), (0, 18.983520978003607), (0, 18.281663729063848), (0, 15.092526262577755), (0, 15.627337626851542), (0, 16.404276613456332), (0, 16.359304328241155), (0, 15.362549111183503), (0, 13.643626153575084)]