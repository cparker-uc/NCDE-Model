Model Setup for {PATIENT_GROUPS} #{INDIVIDUAL_NUMBER} Trained Network:

NCDE Network Architecture Parameters
Input channels=3
Hidden channels=64
Output channels=3

Training hyperparameters
Optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
Training Iterations=150
Learning rate=0.001
Weight decay=0.0
Optimizer reset frequency=None

Dropout probability (after initial linear layer before NCDE): 0.0
Training Data Selection Parameters
(If not virtual, the only important params are the groups and whether data was normalized/standardized)
Patient groups=['Control']
Augmentation strategy=None
Noise Magnitude=0.0
Normalized/standardized=None
Number of virtual patients per real patient=0
Label smoothing factor=0
Test Patient Combinations:
Training batch size=1
Training Results:
Runtime=250.22567701339722
Loss over time=[(0, 98.37239227175816), (0, 68.3365331264347), (0, 44.38232615038703), (0, 52.105703797540095), (0, 51.272138143480845), (0, 36.00639224271082), (0, 17.250479551869415), (0, 13.199818999131475), (0, 12.783136682343823), (0, 10.990996706674999), (0, 11.394752660038383), (0, 10.331538010086533), (0, 13.026829038957388), (0, 12.148391949664395), (0, 12.340585915576263), (0, 11.618070092779547), (0, 10.166378351805225), (0, 9.224759391106778), (0, 8.036178051056732), (0, 7.149304410726174), (0, 5.853053404498915), (0, 5.995070920477834), (0, 5.097970401567435), (0, 4.588844937315224), (0, 4.301859142990857), (0, 4.1486440330648415), (0, 4.034973636401338), (0, 4.0842195627037015), (0, 4.3140252414122235), (0, 3.823764241669364), (0, 4.1735783465771386), (0, 3.8295916610742977), (0, 4.907150774863019), (0, 5.1496738197933665), (0, 5.3619421285483755), (0, 5.486579753523052), (0, 5.050322243393083), (0, 4.875585111400107), (0, 5.100504378575363), (0, 5.111916727360179), (0, 4.663368854063504), (0, 5.270761734339895), (0, 5.4700706494781395), (0, 4.902749186350298), (0, 6.897961935506275), (0, 5.712916200026633), (0, 4.87842642731625), (0, 5.501604936522081), (0, 4.53162042008461), (0, 4.857684871225025), (0, 4.891046168052405), (0, 4.786096987515717), (0, 4.7340954170027665), (0, 4.510355867683816), (0, 4.778440154536983), (0, 4.79321715322603), (0, 4.431024749796604), (0, 4.524046312277143), (0, 4.4190013720094266), (0, 4.856011581360259), (0, 4.596133308409681), (0, 4.620094899924676), (0, 4.545750821607453), (0, 4.539246629732709), (0, 4.705502420419889), (0, 4.738140355384364), (0, 4.638690592075533), (0, 4.834034718670505), (0, 4.853000040669079), (0, 4.957554578227092), (0, 4.795766479230672), (0, 5.071500726549195), (0, 4.89802826539685), (0, 5.135218988851478), (0, 5.151567984484387), (0, 4.997628022107972), (0, 5.18029794372215), (0, 5.237483428178551), (0, 5.46885692718304), (0, 5.454531211627626), (0, 5.368252286770267), (0, 5.405184473516452), (0, 5.8515704313073025), (0, 5.964417433451357), (0, 5.958869823477017), (0, 5.9562067513844275), (0, 6.104471836144377), (0, 6.073569068745978), (0, 6.359208542178098), (0, 6.285148829690013), (0, 6.308852017774829), (0, 6.391080778152489), (0, 6.80659355130794), (0, 6.598535221045285), (0, 6.492924443380249), (0, 6.585072986361769), (0, 6.888754677152399), (0, 7.160783310732344), (0, 9.036665281765194), (0, 7.332803876602941), (0, 7.18882729927808), (0, 7.001763149647566), (0, 7.386946193658841), (0, 7.03402251927574), (0, 6.877116142848777), (0, 10.199162376405525), (0, 7.846819384931517), (0, 7.956653574908285), (0, 7.012335888583453), (0, 6.498062847932793), (0, 7.51510239410572), (0, 7.1285166878626045), (0, 6.230759016805053), (0, 6.78451591392806), (0, 6.917660228780428), (0, 6.407726609393781), (0, 6.671324394876333), (0, 7.057723970779375), (0, 6.945262335510573), (0, 7.090394666435652), (0, 6.887762219465569), (0, 6.813269534765641), (0, 7.152911391910375), (0, 6.749445606732011), (0, 6.981223553354117), (0, 6.932844075310153), (0, 6.928808507958048), (0, 7.092919957079854), (0, 7.320049265736557), (0, 6.71314787658948), (0, 6.930307148898154), (0, 6.91815776207939), (0, 7.400462584179369), (0, 7.145526304088151), (0, 7.196989419461389), (0, 7.068738392092317), (0, 7.582324170363656), (0, 7.0117205165504854), (0, 7.131297522387007), (0, 7.190098093364178), (0, 7.237456198031107), (0, 7.106704813704877), (0, 7.042576328596485), (0, 7.120190016352428), (0, 7.818610748890001), (0, 7.8392751324603545), (0, 7.14532516361266), (0, 7.095003528394451), (0, 7.167631271650311), (0, 7.084303526566412)]