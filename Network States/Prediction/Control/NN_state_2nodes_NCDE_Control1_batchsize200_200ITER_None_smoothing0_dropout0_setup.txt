Model Setup for {PATIENT_GROUPS} Trained Network:

NCDE Network Architecture Parameters
Input channels=2
Hidden channels=2
Output channels=2

Training hyperparameters
Optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-06
)Training Iterations=200
Learning rate=0.001
Weight decay=1e-06
Optimizer reset frequency=None

Dropout probability (after initial linear layer before NCDE): 0
Training Data Selection Parameters
(If not virtual, the only important params are the groups and whether data was normalized/standardized)
Patient groups=['Control']
Augmentation strategy=Uniform
Noise Magnitude=0.05
Normalized/standardized=None
Number of virtual patients per real patient=100
Label smoothing factor=0
Test Patient Combinations:
Control: None
MDD: None
Training batch size=200
Training Results:
Runtime=279.627072095871
Loss over time=[(0, 50.43408833570653), (0, 49.860163146674374), (0, 49.23101769995899), (0, 48.54250747343632), (0, 47.79273455443142), (0, 46.979944547871476), (0, 46.09675997258177), (0, 45.12561851152694), (0, 44.03674639728103), (0, 42.786836853610446), (0, 41.31632391918602), (0, 39.541489745536076), (0, 37.33459868812576), (0, 34.53931135807), (0, 31.044307672734423), (0, 27.483568850571046), (0, 26.153866351032107), (0, 25.680421945260118), (0, 25.319451894360647), (0, 24.98860397223284), (0, 24.687044466417237), (0, 24.418126101965242), (0, 24.185180312347928), (0, 23.965561665360227), (0, 23.76610055846422), (0, 23.585658065336997), (0, 23.42159004409558), (0, 23.271422144515387), (0, 23.132843209739324), (0, 23.0037761513059), (0, 22.88234992113874), (0, 22.76684611382593), (0, 22.65566219680488), (0, 22.547291646384163), (0, 22.441488996668557), (0, 22.34052765918204), (0, 22.24429598127977), (0, 22.147472791706313), (0, 22.057541695476495), (0, 21.9711014195705), (0, 21.881976323139625), (0, 21.782789720446104), (0, 21.665036606332556), (0, 21.49170917286808), (0, 21.22284564337484), (0, 20.991313906120908), (0, 20.4232404496833), (0, 18.885698582706535), (0, 18.77192862629351), (0, 19.04153550733023), (0, 19.12737586330702), (0, 19.104327510907638), (0, 18.971804020899143), (0, 18.698193873002857), (0, 18.193300517394206), (0, 18.258932814583655), (0, 18.279171465073095), (0, 18.2746820487933), (0, 18.241785994749566), (0, 18.18560273746024), (0, 18.11546751616062), (0, 18.037931311896696), (0, 17.955506516322806), (0, 17.883130916886262), (0, 17.808681699236118), (0, 18.04249308387438), (0, 17.82444492853917), (0, 17.73795605602928), (0, 17.734135199983935), (0, 17.724246766728665), (0, 17.709104290399438), (0, 17.68893788644688), (0, 17.6638337528288), (0, 17.633822341867752), (0, 17.598915735854025), (0, 17.559202740169), (0, 17.514865182138838), (0, 17.46612119326471), (0, 17.413208467230454), (0, 17.356230719606877), (0, 17.295138230061806), (0, 17.244899297579483), (0, 17.23288139249081), (0, 17.217530796775847), (0, 17.198945197067616), (0, 17.177356196569942), (0, 17.153075805514497), (0, 17.126462836257385), (0, 17.097897689599247), (0, 17.067764321165686), (0, 17.0364367732406), (0, 17.00427669343434), (0, 16.97162569953365), (0, 16.938812622850435), (0, 16.906178421611415), (0, 16.87411667345216), (0, 16.84288756655116), (0, 16.81217728267279), (0, 16.782021515380233), (0, 16.752458888975482), (0, 16.72350936082788), (0, 16.703334170255975), (0, 16.679687178127956), (0, 16.64450723828642), (0, 16.61736137579139), (0, 16.591866362053608), (0, 16.56607426138752), (0, 16.540016860589457), (0, 16.513728508067768), (0, 16.48724338981243), (0, 16.46059371503941), (0, 16.433809583133918), (0, 16.406918885837708), (0, 16.379941966429065), (0, 16.352894360362516), (0, 16.325786977436312), (0, 16.298626320767568), (0, 16.27141447266264), (0, 16.244149408566646), (0, 16.216825207393), (0, 16.189432425848963), (0, 16.16195819232717), (0, 16.13438676804852), (0, 16.106700072414906), (0, 16.078877216522173), (0, 16.05089521584398), (0, 16.0227292863412), (0, 15.994353226174065), (0, 15.965738826109636), (0, 15.936856577101253), (0, 15.90767592296251), (0, 15.878164881373163), (0, 15.848290270190132), (0, 15.818017870862716), (0, 15.787312463871064), (0, 15.756137769972314), (0, 15.724456291439179), (0, 15.692229242656094), (0, 15.65941713844107), (0, 15.62597868543172), (0, 15.591871668086162), (0, 15.557052566008554), (0, 15.521629740756724), (0, 15.485731674828669), (0, 15.449220360709745), (0, 15.41199046196124), (0, 15.373960424966082), (0, 15.335062465291571), (0, 15.29521869786256), (0, 15.254374481873862), (0, 15.212467173483917), (0, 15.169413429647749), (0, 15.125144081997236), (0, 15.07958723714259), (0, 15.032667576207444), (0, 14.984300099911382), (0, 14.934382794114578), (0, 14.88282244094669), (0, 14.882474193045494), (0, 14.858977815179577), (0, 14.815021143867948), (0, 14.754092221281804), (0, 14.679998755584954), (0, 14.647440996460023), (0, 14.618571815104184), (0, 14.586255416081785), (0, 14.550562570313367), (0, 14.511533936450984), (0, 14.469111311665689), (0, 14.42310205411112), (0, 14.373245113777756), (0, 14.319444454129888), (0, 14.26179870038701), (0, 14.202576706450703), (0, 14.173653584265663), (0, 14.134975738619818), (0, 14.088669826405832), (0, 14.037077500799908), (0, 13.990788978662545), (0, 13.953203726743988), (0, 13.908258804521433), (0, 13.856090840815979), (0, 13.821502870795655), (0, 13.782740379812195), (0, 13.739019548693346), (0, 13.691271284044376), (0, 13.640415741477124), (0, 13.587323080623424), (0, 13.557329517995885), (0, 13.517917694960373), (0, 13.467916881044921), (0, 13.408508158868171), (0, 13.384122445626991), (0, 13.33194279191856), (0, 13.278147790347116), (0, 13.233307847440022), (0, 13.187947225511211), (0, 13.144884624452091), (0, 13.100724718465115), (0, 13.060096373354565)]