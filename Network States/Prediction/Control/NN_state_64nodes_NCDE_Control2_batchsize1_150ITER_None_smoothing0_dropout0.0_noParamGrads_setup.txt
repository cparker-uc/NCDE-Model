Model Setup for {PATIENT_GROUPS} #{INDIVIDUAL_NUMBER} Trained Network:

NCDE Network Architecture Parameters
Input channels=3
Hidden channels=64
Output channels=3

Training hyperparameters
Optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
Training Iterations=150
Learning rate=0.001
Weight decay=0.0
Optimizer reset frequency=None

Dropout probability (after initial linear layer before NCDE): 0.0
Training Data Selection Parameters
(If not virtual, the only important params are the groups and whether data was normalized/standardized)
Patient groups=['Control']
Augmentation strategy=None
Noise Magnitude=0.0
Normalized/standardized=None
Number of virtual patients per real patient=0
Label smoothing factor=0
Test Patient Combinations:
Training batch size=1
Training Results:
Runtime=237.9570460319519
Loss over time=[(0, 46.257546519976735), (0, 44.891594486415634), (0, 24.1248405730899), (0, 10.970105742665352), (0, 17.130055337851516), (0, 16.567426091310086), (0, 13.680893480873266), (0, 12.384222496360168), (0, 9.803266203015673), (0, 7.817694051097141), (0, 9.776001095293827), (0, 8.726778138274268), (0, 9.602139865570779), (0, 6.986625192458739), (0, 6.647450439941946), (0, 6.0052628957701275), (0, 4.99895357513892), (0, 4.272682658073883), (0, 5.135897429630053), (0, 4.310196399768359), (0, 5.242927534841855), (0, 4.8629521922015675), (0, 4.22090300178792), (0, 3.8021461610544782), (0, 4.868838262327444), (0, 5.308360168106618), (0, 4.904280957477375), (0, 4.157721451510297), (0, 3.731823354593954), (0, 4.408648047560551), (0, 4.51142791373768), (0, 4.4531076640578355), (0, 4.643399400209826), (0, 4.188804546706561), (0, 4.4560165788359845), (0, 4.599230281921495), (0, 4.7799229030178445), (0, 4.685372071031868), (0, 4.607161560947028), (0, 4.5643101348829385), (0, 4.244347456510865), (0, 4.356199416557421), (0, 4.481425231577511), (0, 4.38139277636602), (0, 4.744130620729272), (0, 4.752512032772661), (0, 5.012158283668509), (0, 4.767601342611346), (0, 5.251665683216328), (0, 5.256296648051101), (0, 5.229010971171007), (0, 5.223299641758796), (0, 5.181919695806172), (0, 5.384721904729642), (0, 5.548798372248289), (0, 5.725059105057432), (0, 5.467683770955901), (0, 6.127308362359503), (0, 6.046778522466461), (0, 6.405964869598342), (0, 6.498576346809478), (0, 6.172125340469132), (0, 5.896589443773457), (0, 6.466618507901642), (0, 6.279236117006346), (0, 6.007150813239523), (0, 6.59984136823221), (0, 6.883011400227289), (0, 6.700052621397009), (0, 6.39222256814818), (0, 6.392083070950574), (0, 6.409454295762784), (0, 6.486210488644606), (0, 6.844228478327595), (0, 8.184067412662388), (0, 7.286321187369706), (0, 7.085482577123618), (0, 6.652804112248259), (0, 7.1053928298995315), (0, 6.972640704844873), (0, 6.878748072778076), (0, 7.273599932942676), (0, 7.177788509270119), (0, 7.755615150075006), (0, 7.982665715421253), (0, 7.473291182968033), (0, 8.18811345095822), (0, 8.110319255070753), (0, 7.567514067890084), (0, 8.760292183756643), (0, 9.180978154717037), (0, 8.33186953766738), (0, 9.103961173511259), (0, 8.483411450821535), (0, 7.9835708440862545), (0, 8.10563121400669), (0, 8.61409893533092), (0, 9.004381730332781), (0, 8.052314204859083), (0, 7.7790956253545), (0, 7.852834726620137), (0, 7.843784809235776), (0, 8.185189667211745), (0, 8.441249249831044), (0, 8.010081848431541), (0, 7.9887096223473995), (0, 7.86196547546319), (0, 7.94897729944721), (0, 8.078940145192323), (0, 7.989206823694377), (0, 8.04579480209373), (0, 7.844916762649615), (0, 8.019449306357492), (0, 7.891313814217573), (0, 8.59114377240838), (0, 8.44867771447203), (0, 7.861642773532189), (0, 7.886665748104282), (0, 8.282382080798085), (0, 8.556314976127037), (0, 8.26377836955465), (0, 8.426482360713363), (0, 8.185631677338073), (0, 8.140172860741536), (0, 8.371588928696672), (0, 8.32861426121026), (0, 8.52968669777632), (0, 8.100274339483832), (0, 8.223350530283833), (0, 8.163086218954508), (0, 8.535223263954324), (0, 8.401038092860295), (0, 8.308616577779729), (0, 8.189254098832022), (0, 8.202334198225431), (0, 8.2209860227226), (0, 8.309315391782864), (0, 8.323844373026253), (0, 8.270428395924457), (0, 8.28050876616612), (0, 8.480148025937673), (0, 8.503734286709669), (0, 8.670748195372678), (0, 8.565858501676763), (0, 8.624070748756717), (0, 9.292748398366887), (0, 10.04084143177753), (0, 10.71390921071866), (0, 10.139178097355627), (0, 9.75766313103558)]