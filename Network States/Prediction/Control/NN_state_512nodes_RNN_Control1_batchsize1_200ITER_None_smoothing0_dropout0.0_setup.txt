Model Setup for {PATIENT_GROUPS} Trained Network:

RNN Network Architecture Parameters
Input channels=1
Hidden channels=512
Output channels=4

Training hyperparameters
Optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 1e-06
)Training Iterations=200
Learning rate=0.0003
Weight decay=1e-06
Optimizer reset frequency=500

Dropout probability (after initial linear layer before NCDE): 0.0
Training Data Selection Parameters
(If not virtual, the only important params are the groups and whether data was normalized/standardized)
Patient groups=['Control']
Augmentation strategy=Uniform
Noise Magnitude=0.0
Normalized/standardized=None
Number of virtual patients per real patient=1
Label smoothing factor=0
Test Patient Combinations:
Control: None
MDD: None
Training batch size=1
Training Results:
Runtime=143.21468782424927
Loss over time=[(0, 554.8195453260647), (0, 554.0303071037565), (0, 536.9920349003851), (0, 506.0477664217294), (0, 473.15032669640556), (0, 442.9133493817657), (0, 416.8426971616819), (0, 394.971536332637), (0, 376.6316023563539), (0, 361.9439888953211), (0, 350.5793409455939), (0, 341.69562421389077), (0, 334.6086307253654), (0, 328.80720377167876), (0, 323.90249543812087), (0, 319.6254823198112), (0, 315.79626695921604), (0, 312.285196366728), (0, 308.99692324698793), (0, 305.8639148058771), (0, 302.8400283377445), (0, 299.8933337481722), (0, 297.0012215746866), (0, 294.15024004104055), (0, 291.33750174551204), (0, 288.56711873647095), (0, 285.84414817149826), (0, 283.1745036406096), (0, 280.56497423101524), (0, 278.01646296881836), (0, 275.52109320660156), (0, 273.0681384109265), (0, 270.64935506871166), (0, 268.25976980074495), (0, 265.8966174912632), (0, 263.5582286251528), (0, 261.24318453013757), (0, 258.94980704692824), (0, 256.67612942221956), (0, 254.4206105736279), (0, 252.18366973419697), (0, 249.968698927001), (0, 247.78015690545396), (0, 245.6198573410418), (0, 243.4861762793174), (0, 241.37637539016703), (0, 239.28832608796648), (0, 237.22073382048708), (0, 235.17285326570578), (0, 233.14424022191227), (0, 231.13461300326273), (0, 229.14378289114873), (0, 227.17161851088392), (0, 225.21802581048647), (0, 223.28293534146536), (0, 221.36629323562565), (0, 219.46805430624627), (0, 217.58817656713134), (0, 215.72661683359522), (0, 213.88332723041387), (0, 212.05825250166208), (0, 210.25132804625676), (0, 208.46247861283973), (0, 206.69161758852144), (0, 204.93864681290944), (0, 203.2034568444864), (0, 201.48592760238873), (0, 199.78592930408695), (0, 198.10332361928985), (0, 196.4379649631725), (0, 194.78970185809314), (0, 193.15837830211626), (0, 191.54383509412705), (0, 189.94591107777651), (0, 188.3644442784217), (0, 186.79927291717976), (0, 185.25023629344432), (0, 183.71717553165055), (0, 182.1999341904081), (0, 180.69835873320952), (0, 179.21229886050506), (0, 177.74160770304), (0, 176.28614187492568), (0, 174.84576137914772), (0, 173.4203293413936), (0, 172.00971150327), (0, 170.6137752849585), (0, 169.23238787396147), (0, 167.86541162637218), (0, 166.51269044959452), (0, 165.17399761551908), (0, 163.84875060768388), (0, 162.53371172828201), (0, 161.35176368121984), (0, 160.06693617675924), (0, 158.79559280116123), (0, 157.5376373476845), (0, 156.29297239160124), (0, 155.0614994235085), (0, 153.84311899434218), (0, 152.63773086890436), (0, 151.44523418423825), (0, 150.26552760898701), (0, 149.09850949995297), (0, 147.94407805234948), (0, 146.80213144068628), (0, 145.6725679477799), (0, 144.555286080004), (0, 143.45018466754814), (0, 142.35716294908), (0, 141.27612064081313), (0, 140.2069579904966), (0, 139.14957581730775), (0, 138.10387553896174), (0, 137.06975918762254), (0, 136.04712941635205), (0, 135.03588949789477), (0, 134.03594331758845), (0, 133.04719536209333), (0, 132.06955070549412), (0, 131.10291499413904), (0, 130.14719443136002), (0, 129.2022957629932), (0, 128.26812626438002), (0, 127.34459372931043), (0, 126.43160646115888), (0, 125.52907326628538), (0, 124.6369034496209), (0, 123.75500681223703), (0, 122.88329365061142), (0, 122.02167475724464), (0, 121.17006142226131), (0, 120.32836543561787), (0, 119.4964990895736), (0, 118.67437518110569), (0, 117.86190701400675), (0, 117.05900840045705), (0, 116.26559366192271), (0, 115.48157762929512), (0, 114.70687564223081), (0, 113.94140354771861), (0, 113.18507769792014), (0, 112.43781494737976), (0, 111.69953264971203), (0, 110.97014865389251), (0, 110.24958130027936), (0, 109.53774941649479), (0, 108.83457231328083), (0, 108.13996978043404), (0, 107.45386208290553), (0, 106.77616995713288), (0, 106.10681460764887), (0, 105.4457177040001), (0, 104.79280137797976), (0, 104.14798822117696), (0, 103.51120128281669), (0, 102.88236406787225), (0, 102.26140053540807), (0, 101.64823509712451), (0, 101.0427926160584), (0, 100.44499840540661), (0, 99.8547782274399), (0, 99.27205829247286), (0, 98.69676525787082), (0, 98.12882622707143), (0, 97.56816874861073), (0, 97.01472081514399), (0, 96.46841086245979), (0, 95.929167768489), (0, 95.39692085231201), (0, 94.87159987316981), (0, 94.35313502948925), (0, 93.84145695792965), (0, 93.33649673245557), (0, 92.83818586344763), (0, 92.34645629685355), (0, 91.86124041338589), (0, 91.38247102776458), (0, 90.91008138801222), (0, 90.44400517479262), (0, 89.98417650079715), (0, 89.53052991017145), (0, 89.08300037798021), (0, 88.64152330970245), (0, 88.20603454075597), (0, 87.77647033604063), (0, 87.35276738950192), (0, 86.93486282370135), (0, 86.52269418939882), (0, 86.11619946513697), (0, 85.71531705682592), (0, 85.31998579732733), (0, 84.93014494603509), (0, 84.54573418845078), (0, 84.16669363575346), (0, 83.79296382436355), (0, 83.42448571549865), (0, 83.06120069472423), (0, 82.70305057149419), (0, 82.34997757868626)]